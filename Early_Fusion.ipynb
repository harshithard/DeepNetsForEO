{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Early_Fusion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HeJzPGGIlHM-IP4PpWxhiK6QfzoSXMpg",
      "authorship_tag": "ABX9TyMQJV7Akpdtv99MdzXmn9Tr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshithard/DeepNetsForEO/blob/master/Early_Fusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eDKON8hyIEN"
      },
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "from glob import glob\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "import itertools\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler\n",
        "import torch.nn.init\n",
        "from torch.autograd import Variable\n",
        "import logging\n",
        "logging.basicConfig(filename='Flow.log',level=logging.DEBUG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTCXtBl33SKG"
      },
      "source": [
        "cd drive/My Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_HirJEmE5RM"
      },
      "source": [
        "# Parameters\n",
        "WINDOW_SIZE = (256, 256) # Patch size\n",
        "STRIDE = 32 # Stride for testing\n",
        "IN_CHANNELS = 3 # Number of input channels (e.g. RGB)\n",
        "FOLDER = \"./ISPRS_dataset/\" # Replace with your \"/path/to/the/ISPRS/dataset/folder/\"\n",
        "BATCH_SIZE = 10 # Number of samples in a mini-batch\n",
        "\n",
        "LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] # Label names\n",
        "N_CLASSES = len(LABELS) # Number of classes\n",
        "WEIGHTS = torch.ones(N_CLASSES) # Weights for class balancing\n",
        "CACHE = True # Store the dataset in-memory\n",
        "\n",
        "DATA_FOLDER = './ISPRS_Vaihingen/'+ 'top_mosaic_09cm_area{}.tif'\n",
        "LABEL_FOLDER = './ISPRS_Vaihingen_ground_truth/' + 'top_mosaic_09cm_area{}.tif'\n",
        "ERODED_FOLDER = './ISPRS_Vaihingen_eroded/' + 'top_mosaic_09cm_area{}_noBoundary.tif'\n",
        "DSM_FOLDER = './normalized_DSMs/' + 'dsm_09cm_matching_area{}_normalized.jpg'   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw01XDv80eqR"
      },
      "source": [
        "# ISPRS color palette\n",
        "# Let's define the standard ISPRS color palette\n",
        "palette = {0 : (255, 255, 255), # Impervious surfaces (white)\n",
        "           1 : (0, 0, 255),     # Buildings (blue)\n",
        "           2 : (0, 255, 255),   # Low vegetation (cyan)\n",
        "           3 : (0, 255, 0),     # Trees (green)\n",
        "           4 : (255, 255, 0),   # Cars (yellow)\n",
        "           5 : (255, 0, 0),     # Clutter (red)\n",
        "           6 : (0, 0, 0)}       # Undefined (black)\n",
        "\n",
        "invert_palette = {v: k for k, v in palette.items()}\n",
        "\n",
        "def convert_to_color(arr_2d, palette=palette):\n",
        "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
        "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = arr_2d == c\n",
        "        arr_3d[m] = i\n",
        "\n",
        "    return arr_3d\n",
        "\n",
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "        arr_2d[m] = i\n",
        "\n",
        "    return arr_2d\n",
        "\n",
        "# We load one tile from the dataset and we display it\n",
        "img = io.imread('./ISPRS_Vaihingen/top_mosaic_09cm_area11.tif')\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(121)\n",
        "plt.imshow(img)\n",
        "\n",
        "# We load the ground truth\n",
        "gt = io.imread('./ISPRS_Vaihingen_ground_truth/top_mosaic_09cm_area11.tif')\n",
        "fig.add_subplot(122)\n",
        "plt.imshow(gt)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# We also check that we can convert the ground truth into an array format\n",
        "array_gt = convert_from_color(gt)\n",
        "print(\"Ground truth in numerical format has shape ({},{}) : \\n\".format(*array_gt.shape[:2]), array_gt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgJ1k3qGEQrh"
      },
      "source": [
        "def get_random_pos(img, window_shape):\n",
        "    \"\"\" Extract of 2D random patch of shape window_shape in the image \"\"\"\n",
        "    w, h = window_shape\n",
        "    W, H = img.shape[-2:]\n",
        "    x1 = random.randint(0, W - w - 1)\n",
        "    x2 = x1 + w\n",
        "    y1 = random.randint(0, H - h - 1)\n",
        "    y2 = y1 + h\n",
        "    return x1, x2, y1, y2\n",
        "\n",
        "def CrossEntropy2d(input, target, weight=None, size_average=True):\n",
        "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
        "    dim = input.dim()\n",
        "    logging.info(\"input dim is : \"+str(type(dim)))\n",
        "    output = input.view(input.size(0),input.size(1), -1)\n",
        "    output = torch.transpose(output,1,2).contiguous()\n",
        "    output = output.view(-1,output.size(2))\n",
        "    target = target.view(-1)\n",
        "    target=target.long()\n",
        "    return F.cross_entropy(output, target, weight, size_average)\n",
        "    \"\"\"\n",
        "    if dim == 2:\n",
        "        return F.cross_entropy(input, target, weight, size_average)\n",
        "    elif dim == 4:\n",
        "        output = input.view(input.size(0),input.size(1), -1)\n",
        "        output = torch.transpose(output,1,2).contiguous()\n",
        "        output = output.view(-1,output.size(2))\n",
        "        target = target.view(-1)\n",
        "        return F.cross_entropy(output, target,weight, size_average)\n",
        "    else:\n",
        "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
        "    \"\"\"\n",
        "\n",
        "def accuracy(input, target):\n",
        "    return 100 * float(np.count_nonzero(input == target)) / target.size\n",
        "\n",
        "def sliding_window(top, step=10, window_size=(20,20)):\n",
        "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
        "    for x in range(0, top.shape[0], step):\n",
        "        if x + window_size[0] > top.shape[0]:\n",
        "            x = top.shape[0] - window_size[0]\n",
        "        for y in range(0, top.shape[1], step):\n",
        "            if y + window_size[1] > top.shape[1]:\n",
        "                y = top.shape[1] - window_size[1]\n",
        "            yield x, y, window_size[0], window_size[1]\n",
        "            \n",
        "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
        "    \"\"\" Count the number of windows in an image \"\"\"\n",
        "    c = 0\n",
        "    for x in range(0, top.shape[0], step):\n",
        "        if x + window_size[0] > top.shape[0]:\n",
        "            x = top.shape[0] - window_size[0]\n",
        "        for y in range(0, top.shape[1], step):\n",
        "            if y + window_size[1] > top.shape[1]:\n",
        "                y = top.shape[1] - window_size[1]\n",
        "            c += 1\n",
        "    return c\n",
        "\n",
        "def grouper(n, iterable):\n",
        "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
        "    it = iter(iterable)\n",
        "    while True:\n",
        "        chunk = tuple(itertools.islice(it, n))\n",
        "        if not chunk:\n",
        "            return\n",
        "        yield chunk \n",
        "\n",
        "def metrics(predictions, gts, label_values=LABELS):\n",
        "    cm = confusion_matrix(\n",
        "            gts,\n",
        "            predictions,\n",
        "            range(len(label_values)))\n",
        "    \n",
        "    print(\"Confusion matrix :\")\n",
        "    print(cm)\n",
        "    \n",
        "    print(\"---\")\n",
        "    \n",
        "    # Compute global accuracy\n",
        "    total = sum(sum(cm))\n",
        "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
        "    accuracy *= 100 / float(total)\n",
        "    print(\"{} pixels processed\".format(total))\n",
        "    print(\"Total accuracy : {}%\".format(accuracy))\n",
        "    \n",
        "    print(\"---\")\n",
        "    \n",
        "    # Compute F1 score\n",
        "    F1Score = np.zeros(len(label_values))\n",
        "    for i in range(len(label_values)):\n",
        "        try:\n",
        "            F1Score[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))\n",
        "        except:\n",
        "            # Ignore exception if there is no element in class i for test set\n",
        "            pass\n",
        "    print(\"F1Score :\")\n",
        "    for l_id, score in enumerate(F1Score):\n",
        "        print(\"{}: {}\".format(label_values[l_id], score))\n",
        "\n",
        "    print(\"---\")\n",
        "        \n",
        "    # Compute kappa coefficient\n",
        "    total = np.sum(cm)\n",
        "    pa = np.trace(cm) / float(total)\n",
        "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / float(total*total)\n",
        "    kappa = (pa - pe) / (1 - pe);\n",
        "    print(\"Kappa: \" + str(kappa))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKWkgYjs3n93"
      },
      "source": [
        "# Dataset class\n",
        "\n",
        "class ISPRS_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ids, data_files=DATA_FOLDER, label_files=LABEL_FOLDER,\n",
        "                            cache=False, augmentation=True):\n",
        "        super(ISPRS_dataset, self).__init__()\n",
        "        \n",
        "        self.augmentation = augmentation\n",
        "        self.cache = cache\n",
        "        \n",
        "        # List of files\n",
        "        self.data_files = [DATA_FOLDER.format(id) for id in ids]\n",
        "        self.label_files = [LABEL_FOLDER.format(id) for id in ids]\n",
        "        self.dsm_files = [DSM_FOLDER.format(id) for id in ids]\n",
        "\n",
        "        # Sanity check : raise an error if some files do not exist\n",
        "        for f in self.data_files + self.label_files:\n",
        "            if not os.path.isfile(f):\n",
        "                raise KeyError('{} is not a file !'.format(f))\n",
        "        \n",
        "        # Initialize cache dicts\n",
        "        self.data_cache_ = {}\n",
        "        self.label_cache_ = {}\n",
        "        self.dsm_cache_ = {}\n",
        "            \n",
        "    \n",
        "    def __len__(self):\n",
        "        # Default epoch size is 10 000 samples\n",
        "        return 10000\n",
        "    \n",
        "    @classmethod\n",
        "    def data_augmentation(cls, *arrays, flip=True, mirror=True):\n",
        "        will_flip, will_mirror = False, False\n",
        "        if flip and random.random() < 0.5:\n",
        "            will_flip = True\n",
        "        if mirror and random.random() < 0.5:\n",
        "            will_mirror = True\n",
        "        \n",
        "        results = []\n",
        "        for array in arrays:\n",
        "            if will_flip:\n",
        "                if len(array.shape) == 2:\n",
        "                    array = array[::-1, :]\n",
        "                else:\n",
        "                    array = array[:, ::-1, :]\n",
        "            if will_mirror:\n",
        "                if len(array.shape) == 2:\n",
        "                    array = array[:, ::-1]\n",
        "                else:\n",
        "                    array = array[:, :, ::-1]\n",
        "            results.append(np.copy(array))\n",
        "            \n",
        "        return tuple(results)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        # Pick a random image from test data\n",
        "        random_idx = random.randint(0, len(self.data_files) - 1)\n",
        "       \n",
        "        \n",
        "        \n",
        "        # If the tile hasn't been loaded yet, put in cache\n",
        "        if random_idx in self.data_cache_.keys():\n",
        "            data = self.data_cache_[random_idx]\n",
        "            \n",
        "        else:\n",
        "            # Data is normalized in [0, 1]\n",
        "            data = 1/255 * np.asarray(io.imread(self.data_files[random_idx]).transpose((2,0,1)), dtype='float32')\n",
        "            if self.cache:\n",
        "                self.data_cache_[random_idx] = data\n",
        "            \n",
        "        if random_idx in self.label_cache_.keys():\n",
        "            label = self.label_cache_[random_idx]\n",
        "            \n",
        "        else: \n",
        "            # Labels are converted from IRRG to their numeric values\n",
        "            label = np.asarray(convert_from_color(io.imread(self.label_files[random_idx])), dtype='int64')\n",
        "            if self.cache:\n",
        "                self.label_cache_[random_idx] = label\n",
        "                \n",
        "\n",
        "        if random_idx in self.dsm_cache_.keys():\n",
        "            dsm = self.dsm_cache_[random_idx]\n",
        "            \n",
        "        else: \n",
        "            # Labels are converted from DSM to their numeric values\n",
        "            #logging.info(str( np.asarray(convert_from_color(io.imread(self.dsm_files[random_idx])), dtype='int64')))\n",
        "            dsm =  np.asarray((io.imread(self.dsm_files[random_idx])), dtype='int64')\n",
        "            if self.cache:\n",
        "                self.dsm_cache_[random_idx] = dsm\n",
        "\n",
        "        # Get a random patch\n",
        "        x1, x2, y1, y2 = get_random_pos(data, WINDOW_SIZE)\n",
        "        data_p = data[:, x1:x2,y1:y2]\n",
        "        label_p = label[x1:x2,y1:y2]\n",
        "        dsm_p = dsm[x1:x2,y1:y2]\n",
        "      \n",
        "        \n",
        "        # Data augmentation\n",
        "        data_p, label_p, dsm_p = self.data_augmentation(data_p, label_p, dsm_p)\n",
        "        # Return the torch.Tensor values\n",
        "        return (torch.from_numpy(data_p),\n",
        "                torch.from_numpy(dsm_p),\n",
        "                torch.from_numpy(label_p)\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sAw_EsBFDhx"
      },
      "source": [
        "class SegNet(nn.Module):\n",
        "    # SegNet network\n",
        "    @staticmethod\n",
        "    def weight_init(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.kaiming_normal(m.weight.data)\n",
        "    \n",
        "    def __init__(self, in_channels=IN_CHANNELS, out_channels=N_CLASSES):\n",
        "        super(SegNet, self).__init__()\n",
        "        logging.info(\"Entered init of SegNet\")\n",
        "        self.pool = nn.MaxPool2d(2, return_indices=True)\n",
        "        self.unpool = nn.MaxUnpool2d(2)\n",
        "        \n",
        "        self.conv1_1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
        "        self.conv1_1_bn = nn.BatchNorm2d(64)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv1_2_bn = nn.BatchNorm2d(64)\n",
        "        \n",
        "        self.conv1_1_y = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.conv1_1_bn_y = nn.BatchNorm2d(64)\n",
        "        self.conv1_2_y = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv1_2_bn_y = nn.BatchNorm2d(64)\n",
        "        logging.info(\"Entered 1st block of SegNet\")\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv2_1_bn = nn.BatchNorm2d(128)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv2_2_bn = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv2_1_y = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv2_1_bn_y = nn.BatchNorm2d(128)\n",
        "        self.conv2_2_y = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv2_2_bn_y = nn.BatchNorm2d(128)\n",
        "        logging.info(\"Entered 2nd block of SegNet\")\n",
        "        \n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3_1_bn = nn.BatchNorm2d(256)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv3_2_bn = nn.BatchNorm2d(256)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv3_3_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv3_1_y = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3_1_bn_y = nn.BatchNorm2d(256)\n",
        "        self.conv3_2_y = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv3_2_bn_y = nn.BatchNorm2d(256)\n",
        "        self.conv3_3_y = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv3_3_bn_y = nn.BatchNorm2d(256)\n",
        "        logging.info(\"Entered 3rd block of SegNet\")\n",
        "        \n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv4_1_bn = nn.BatchNorm2d(512)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv4_2_bn = nn.BatchNorm2d(512)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv4_3_bn = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv4_1_y = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv4_1_bn_y = nn.BatchNorm2d(512)\n",
        "        self.conv4_2_y = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv4_2_bn_y = nn.BatchNorm2d(512)\n",
        "        self.conv4_3_y = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv4_3_bn_y = nn.BatchNorm2d(512)\n",
        "        logging.info(\"Entered 4th block of SegNet\")\n",
        "        \n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_1_bn = nn.BatchNorm2d(512)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_2_bn = nn.BatchNorm2d(512)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_3_bn = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv5_1_y = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_1_bn_y = nn.BatchNorm2d(512)\n",
        "        self.conv5_2_y = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_2_bn_y = nn.BatchNorm2d(512)\n",
        "        self.conv5_3_y = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_3_bn_y = nn.BatchNorm2d(512)\n",
        "        logging.info(\"Entered 5th block of SegNet\")\n",
        "\n",
        "        self.conv5_3_D = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_3_D_bn = nn.BatchNorm2d(512)\n",
        "        self.conv5_2_D = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_2_D_bn = nn.BatchNorm2d(512)\n",
        "        self.conv5_1_D = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv5_1_D_bn = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv4_3_D = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv4_3_D_bn = nn.BatchNorm2d(512)\n",
        "        self.conv4_2_D = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.conv4_2_D_bn = nn.BatchNorm2d(512)\n",
        "        self.conv4_1_D = nn.Conv2d(512, 256, 3, padding=1)\n",
        "        self.conv4_1_D_bn = nn.BatchNorm2d(256)\n",
        "        logging.info(\"Entered 6th block of SegNet\")\n",
        "        \n",
        "        self.conv3_3_D = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv3_3_D_bn = nn.BatchNorm2d(256)\n",
        "        self.conv3_2_D = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.conv3_2_D_bn = nn.BatchNorm2d(256)\n",
        "        self.conv3_1_D = nn.Conv2d(256, 128, 3, padding=1)\n",
        "        self.conv3_1_D_bn = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.conv2_2_D = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.conv2_2_D_bn = nn.BatchNorm2d(128)\n",
        "        self.conv2_1_D = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.conv2_1_D_bn = nn.BatchNorm2d(64)\n",
        "        \n",
        "        self.conv1_2_D = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.conv1_2_D_bn = nn.BatchNorm2d(64)\n",
        "        self.conv1_1_D = nn.Conv2d(64, out_channels, 3, padding=1)\n",
        "        \n",
        "        self.apply(self.weight_init)\n",
        "        \n",
        "    def forward(self, image, dsm):\n",
        "        logging.info(\"entered forward\") \n",
        "        x=image.cuda()\n",
        "        y=dsm.float().cuda()\n",
        "        # Encoder block 1 DSM\n",
        "        y = self.conv1_1_bn_y(F.relu(self.conv1_1_y(y)))\n",
        "        y = self.conv1_2_bn_y(F.relu(self.conv1_2_y(y)))\n",
        "        logging.info(\"y shape \"+str(np.shape(y)))\n",
        "\n",
        "        # Encoder block 1' IRRG\n",
        "        x = self.conv1_1_bn(F.relu(self.conv1_1(x)))\n",
        "        x = self.conv1_2_bn(F.relu(self.conv1_2(x)))\n",
        "        x = torch.cat((x,y), dim = 0) \n",
        "        y, mask12 = self.pool(y)\n",
        "        x, mask1 = self.pool(x)\n",
        "        logging.info(\"x shape\"+str(np.shape(x)))\n",
        "\n",
        "        # Encoder block 2 DSM\n",
        "        y = self.conv2_1_bn_y(F.relu(self.conv2_1_y(y)))\n",
        "        y = self.conv2_2_bn_y(F.relu(self.conv2_2_y(y)))\n",
        "        \n",
        "        #logging.info(\"Value of y\"+str(y))\n",
        "        \n",
        "        # Encoder block 2' IRRG\n",
        "        x = self.conv2_1_bn(F.relu(self.conv2_1(x)))\n",
        "        x = self.conv2_2_bn(F.relu(self.conv2_2(x)))\n",
        "        x = torch.cat((x,y),dim=0) \n",
        "        y, mask22 = self.pool(y)\n",
        "        x, mask2 = self.pool(x)\n",
        "        #logging.info(\"Value of x\"+str(x))\n",
        "\n",
        "        # Encoder block 3 DSM\n",
        "        y = self.conv3_1_bn_y(F.relu(self.conv3_1_y(y)))\n",
        "        y = self.conv3_2_bn_y(F.relu(self.conv3_2_y(y)))\n",
        "        y = self.conv3_3_bn_y(F.relu(self.conv3_3_y(y)))\n",
        "        \n",
        "        #logging.info(\"Value of y\"+str(y))\n",
        "        \n",
        "        # Encoder block 3' IRRG\n",
        "        x = self.conv3_1_bn(F.relu(self.conv3_1(x)))\n",
        "        x = self.conv3_2_bn(F.relu(self.conv3_2(x)))\n",
        "        x = self.conv3_3_bn(F.relu(self.conv3_3(x)))\n",
        "        x = torch.cat((x,y),dim=0)\n",
        "        y, mask32 = self.pool(y) \n",
        "        x, mask3 = self.pool(x)\n",
        "        #logging.info(\"Value of x\"+str(x))\n",
        "        \n",
        "        # Encoder block 4 DSM\n",
        "        y = self.conv4_1_bn_y(F.relu(self.conv4_1_y(y)))\n",
        "        y = self.conv4_2_bn_y(F.relu(self.conv4_2_y(y)))\n",
        "        y = self.conv4_3_bn_y(F.relu(self.conv4_3_y(y)))\n",
        "        \n",
        "        #logging.info(\"Value of y\"+str(y))\n",
        "\n",
        "        # Encoder block 4' IRRG\n",
        "        x = self.conv4_1_bn(F.relu(self.conv4_1(x)))\n",
        "        x = self.conv4_2_bn(F.relu(self.conv4_2(x)))\n",
        "        x = self.conv4_3_bn(F.relu(self.conv4_3(x)))\n",
        "        x = torch.cat((x,y),dim=0) \n",
        "        logging.info(\"size of x after cat before pool 4:\" + str(np.shape(x)))\n",
        "        y, mask42 = self.pool(y)\n",
        "        x, mask4 = self.pool(x)\n",
        "        logging.info(\"size of x after block 4 pool:\" + str(np.shape(x)))\n",
        "        logging.info(\"size of mask4 :\" + str(np.shape(mask4)))\n",
        "        #logging.info(\"Value of x\"+str(x))\n",
        "        \n",
        "        # Encoder block 5 DSM\n",
        "        y = self.conv5_1_bn_y(F.relu(self.conv5_1_y(y)))\n",
        "        y = self.conv5_2_bn_y(F.relu(self.conv5_2_y(y)))\n",
        "        y = self.conv5_3_bn_y(F.relu(self.conv5_3_y(y)))\n",
        "        \n",
        "        #logging.info(\"Value of y\"+str(y))\n",
        "\n",
        "        # Encoder block 5' IRRG\n",
        "        x = self.conv5_1_bn(F.relu(self.conv5_1(x)))\n",
        "        x = self.conv5_2_bn(F.relu(self.conv5_2(x)))\n",
        "        x = self.conv5_3_bn(F.relu(self.conv5_3(x)))\n",
        "        x = torch.cat((x,y),dim=0) \n",
        "        logging.info(\"size of x after cat before pool 5:\" + str(np.shape(x)))\n",
        "        y, mask52 = self.pool(y)\n",
        "        x, mask5 = self.pool(x)\n",
        "        logging.info(\"size of mask5:\" + str(np.shape(mask5)))\n",
        "        logging.info(\"size of x after pooling :\" + str(np.shape(x)))\n",
        "        \n",
        "        # Decoder block 5\n",
        "        x = self.unpool(x, mask5)\n",
        "        x = self.conv5_3_D_bn(F.relu(self.conv5_3_D(x)))\n",
        "        x = self.conv5_2_D_bn(F.relu(self.conv5_2_D(x)))\n",
        "        x = self.conv5_1_D_bn(F.relu(self.conv5_1_D(x)))\n",
        "        logging.info(\"size of x after one decode:\" + str(np.shape(x)))\n",
        "        x = x[:50 , : , :, :]\n",
        "        logging.info(\"x shape after comedy is : \"+str(np.shape(x)))\n",
        "\n",
        "        # Decoder block 4\n",
        "        x = self.unpool(x, mask4)\n",
        "        x = self.conv4_3_D_bn(F.relu(self.conv4_3_D(x)))\n",
        "        x = self.conv4_2_D_bn(F.relu(self.conv4_2_D(x)))\n",
        "        x = self.conv4_1_D_bn(F.relu(self.conv4_1_D(x)))\n",
        "        x = x[:40 , : , :, :]\n",
        "        logging.info(\"size of x after 2 decode :\" + str(np.shape(x)))\n",
        "        #x = np.reshape(x,(40,512,16,16))\n",
        "\n",
        "        # Decoder block 3\n",
        "        x = self.unpool(x, mask3)\n",
        "        x = self.conv3_3_D_bn(F.relu(self.conv3_3_D(x)))\n",
        "        x = self.conv3_2_D_bn(F.relu(self.conv3_2_D(x)))\n",
        "        x = self.conv3_1_D_bn(F.relu(self.conv3_1_D(x)))\n",
        "        x = x[:30 , : , :, :]\n",
        "        \n",
        "        # Decoder block 2\n",
        "        x = self.unpool(x, mask2)\n",
        "        x = self.conv2_2_D_bn(F.relu(self.conv2_2_D(x)))\n",
        "        x = self.conv2_1_D_bn(F.relu(self.conv2_1_D(x)))\n",
        "        x = x[:20 , : , :, :]\n",
        "        \n",
        "        # Decoder block 1\n",
        "        x = self.unpool(x, mask1)\n",
        "        x = self.conv1_2_D_bn(F.relu(self.conv1_2_D(x)))\n",
        "        x = x[:10 , : , :, :]\n",
        "        x = F.log_softmax(self.conv1_1_D(x))\n",
        "\n",
        "        #logging.info(\"Value of x \"+str(x))\n",
        "        #logging.info(\"Value of y \"+str(y))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EerMZ1CMFJYY"
      },
      "source": [
        "# instantiate the network\n",
        "net = SegNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nvWBIioAxwc"
      },
      "source": [
        "import os\n",
        "try:\n",
        "    from urllib.request import URLopener\n",
        "except ImportError:\n",
        "    from urllib import URLopener\n",
        "\n",
        "# Download VGG-16 weights from PyTorch\n",
        "vgg_url = 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth'\n",
        "if not os.path.isfile('./vgg16_bn-6c64b313.pth'):\n",
        "    weights = URLopener().retrieve(vgg_url, './vgg16_bn-6c64b313.pth')\n",
        "\n",
        "vgg16_weights = torch.load('./vgg16_bn-6c64b313.pth')\n",
        "mapped_weights = {}\n",
        "for k_vgg, k_segnet in zip(vgg16_weights.keys(), net.state_dict().keys()):\n",
        "    if \"features\" in k_vgg:\n",
        "        mapped_weights[k_segnet] = vgg16_weights[k_vgg]\n",
        "        print(\"Mapping {} to {}\".format(k_vgg, k_segnet))\n",
        "        \n",
        "try:\n",
        "    net.load_state_dict(mapped_weights)\n",
        "    print(\"Loaded VGG-16 weights in SegNet !\")\n",
        "except:\n",
        "    # Ignore missing keys\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QdhGeqjFRHB"
      },
      "source": [
        "net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKgLJAUFYXe"
      },
      "source": [
        "# Load the datasets\n",
        "\n",
        "all_files = sorted(glob(LABEL_FOLDER.replace('{}', '*')))\n",
        "all_ids = [f.split('area')[-1].split('.')[0] for f in all_files]\n",
        "\n",
        "# Random tile numbers for train/test split\n",
        "#train_ids = random.sample(all_ids, 2 * len(all_ids) // 3 + 1)\n",
        "#test_ids = list(set(all_ids) - set(train_ids))\n",
        "\n",
        "# Exemple of a train/test split on Vaihingen :\n",
        "train_ids = ['1', '3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\n",
        "test_ids = ['5', '21', '15', '30'] \n",
        "\n",
        "print(\"Tiles for training : \", train_ids)\n",
        "print(\"Tiles for testing : \", test_ids)\n",
        "\n",
        "train_set = ISPRS_dataset(train_ids, cache=CACHE)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE)\n",
        "for i in enumerate(train_loader):\n",
        "  logging.info(i)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCuCgZ-6HcAM"
      },
      "source": [
        "base_lr = 0.0085\n",
        "params_dict = dict(net.named_parameters())\n",
        "params = []\n",
        "for key, value in params_dict.items():\n",
        "    if '_D' in key:\n",
        "        # Decoder weights are trained at the nominal learning rate\n",
        "        params += [{'params':[value],'lr': base_lr}]\n",
        "    else:\n",
        "        # Encoder weights are trained at lr / 2 (we have VGG-16 weights as initialization)\n",
        "        params += [{'params':[value],'lr': base_lr / 2}]\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0005)\n",
        "# We define the scheduler\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [25, 35, 45], gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpmrT8g0HfA9"
      },
      "source": [
        "def test(net, test_ids, all=False, stride=WINDOW_SIZE[0], batch_size=BATCH_SIZE, window_size=WINDOW_SIZE):\n",
        "    # Use the network on the test set\n",
        "    test_images = (1 / 255 * np.asarray(io.imread(DATA_FOLDER.format(id)), dtype='float32') for id in test_ids)\n",
        "    test_labels = (np.asarray(io.imread(LABEL_FOLDER.format(id)), dtype='uint8') for id in test_ids)\n",
        "    test_dsm =  (np.asarray(io.imread(DSM_FOLDER.format(id)), dtype='uint8') for id in test_ids)\n",
        "    eroded_labels = (convert_from_color(io.imread(ERODED_FOLDER.format(id))) for id in test_ids)\n",
        "    all_preds = []\n",
        "    all_gts = []\n",
        "    \n",
        "    # Switch the network to inference mode\n",
        "    net.eval()\n",
        "\n",
        "    for img, gt, gt_e, dsm in tqdm(zip(test_images, test_labels, eroded_labels , test_dsm), total=len(test_ids), leave=False):\n",
        "        pred = np.zeros(img.shape[:2] + (N_CLASSES,))\n",
        "\n",
        "        total = count_sliding_window(img, step=stride, window_size=window_size) // batch_size\n",
        "        for i, coords in enumerate(tqdm(grouper(batch_size, sliding_window(img, step=stride, window_size=window_size)), total=total, leave=False)):\n",
        "            # Display in progress results\n",
        "            if i > 0 and total > 10 and i % int(10 * total / 100) == 0:\n",
        "                    _pred = np.argmax(pred, axis=-1)\n",
        "                    fig = plt.figure()\n",
        "                    fig.add_subplot(1,3,1)\n",
        "                    plt.imshow(np.asarray(255 * img, dtype='uint8'))\n",
        "                    fig.add_subplot(1,3,2)\n",
        "                    plt.imshow(convert_to_color(_pred))\n",
        "                    fig.add_subplot(1,3,3)\n",
        "                    plt.imshow(gt)\n",
        "                    clear_output()\n",
        "                    plt.show()\n",
        "                    \n",
        "            # Build the tensor\n",
        "            image_patches = [np.copy(img[x:x+w, y:y+h]).transpose((2,0,1)) for x,y,w,h in coords]\n",
        "            image_patches = torch.FloatTensor(image_patches).cpu()\n",
        "            image_patches = np.asarray(image_patches)\n",
        "            image_patches = Variable(torch.from_numpy(image_patches).cuda(), volatile=True)\n",
        "\n",
        "            # Build the tensor\n",
        "            logging.info(\"Look hereeeeee dsm shape : \"+ str(np.shape(dsm)))\n",
        "            image_patches_dsm = [np.copy(dsm[x:x+w, y:y+h]) for x,y,w,h in coords]\n",
        "            image_patches_dsm = torch.FloatTensor(image_patches_dsm).cpu()\n",
        "            image_patches_dsm = np.asarray(image_patches_dsm)\n",
        "            image_patches_dsm = np.reshape(image_patches_dsm,(10,1,256,256))\n",
        "            image_patches_dsm = Variable(torch.from_numpy(image_patches_dsm).cuda(), volatile=True)\n",
        "            \n",
        "            # Do the inference\n",
        "            outs = net(image_patches, image_patches_dsm)\n",
        "            logging.info(\"outs is \"+str(outs))\n",
        "            outs = outs.data.cpu().numpy()\n",
        "            \n",
        "            # Fill in the results array\n",
        "            for out, (x, y, w, h) in zip(outs, coords):\n",
        "                out = out.transpose((1,2,0))\n",
        "                pred[x:x+w, y:y+h] += out\n",
        "            del(outs)\n",
        "\n",
        "        pred = np.argmax(pred, axis=-1)\n",
        "\n",
        "        # Display the result\n",
        "        clear_output()\n",
        "        fig = plt.figure()\n",
        "        fig.add_subplot(1,3,1)\n",
        "        plt.imshow(np.asarray(255 * img, dtype='uint8'))\n",
        "        fig.add_subplot(1,3,2)\n",
        "        plt.imshow(convert_to_color(pred))\n",
        "        fig.add_subplot(1,3,3)\n",
        "        plt.imshow(gt)\n",
        "        plt.show()\n",
        "\n",
        "        all_preds.append(pred)\n",
        "        all_gts.append(gt_e)\n",
        "\n",
        "        clear_output()\n",
        "        # Compute some metrics\n",
        "        metrics(pred.ravel(), gt_e.ravel())\n",
        "        accuracy = metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel())\n",
        "    if all:\n",
        "        return accuracy, all_preds, all_gts\n",
        "    else:\n",
        "        return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnh2B-pBHiUL"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def train(net, optimizer, epochs, scheduler=None, weights=WEIGHTS, save_epoch = 15):\n",
        "    losses = np.zeros(1000000)\n",
        "    mean_losses = np.zeros(100000000)\n",
        "    weights = weights.cuda()\n",
        "\n",
        "    criterion = nn.NLLLoss2d(weight=weights)\n",
        "    iter_ = 0\n",
        "    \n",
        "    for e in range(1, epochs + 1):\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        net.train()\n",
        "        for batch_idx, (data,dsm_data,target) in enumerate(train_loader):\n",
        "            data, dsm_data, target = Variable(data.cuda()),Variable(dsm_data.cuda()) ,Variable(target.cuda())\n",
        "            optimizer.zero_grad()\n",
        "            logging.info(\"DSM shape:\"+ str(np.shape(dsm_data)))\n",
        "            dsm_data=np.reshape(dsm_data.cpu(),(10,1,256,256))\n",
        "            logging.info(\"data shape is \"+ str(np.shape(data)))\n",
        "            logging.info(\"dsm_data shape is \"+ str(np.shape(dsm_data)))\n",
        "            output = net(data,dsm_data)\n",
        "            loss = CrossEntropy2d(output, target, weight=weights)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_data=loss.cpu().data.numpy()\n",
        "            print(\"loss_data isss\",loss_data)\n",
        "            \n",
        "            losses[iter_] = loss_data\n",
        "            mean_losses[iter_] = np.mean(losses[max(0,iter_-100):iter_])\n",
        "            \n",
        "            if iter_ % 100 == 0:\n",
        "                clear_output()\n",
        "                rgb = np.asarray(255 * np.transpose(data.data.cpu().numpy()[0],(1,2,0)), dtype='uint8')\n",
        "                pred = np.argmax(output.data.cpu().numpy()[0], axis=0)\n",
        "                gt = target.data.cpu().numpy()[0]\n",
        "                print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}'.format(\n",
        "                    e, epochs, batch_idx, len(train_loader),\n",
        "                    100. * batch_idx / len(train_loader), loss_data, accuracy(pred, gt)))\n",
        "                plt.plot(mean_losses[:iter_]) and plt.show()\n",
        "                fig = plt.figure()\n",
        "                fig.add_subplot(131)\n",
        "                plt.imshow(rgb)\n",
        "                plt.title('RGB')\n",
        "                fig.add_subplot(132)\n",
        "                plt.imshow(convert_to_color(gt))\n",
        "                plt.title('Ground truth')\n",
        "                fig.add_subplot(133)\n",
        "                plt.title('Prediction')\n",
        "                plt.imshow(convert_to_color(pred))\n",
        "                plt.show()\n",
        "            iter_ += 1\n",
        "            \n",
        "            del(data, target, loss)\n",
        "            \n",
        "        if e % save_epoch == 0:\n",
        "            # We validate with the largest possible stride for faster computing\n",
        "            acc = test(net, test_ids, all=False, stride=min(WINDOW_SIZE))\n",
        "            torch.save(net.state_dict(), './segnet256_epoch{}_{}'.format(e, acc))\n",
        "    torch.save(net.state_dict(), './segnet_final')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHCCDehwHmnx"
      },
      "source": [
        "train(net, optimizer, 15, scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6iXt22LHpNg"
      },
      "source": [
        "Snet.load_state_dict(torch.load('./segnet_final'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S30-huyRHtLH"
      },
      "source": [
        "_, all_preds, all_gts = test(net, test_ids, all=True, stride=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5qS7uCJHvBv"
      },
      "source": [
        "\n",
        "for p, id_ in zip(all_preds, test_ids):\n",
        "    img = convert_to_color(p)\n",
        "    plt.imshow(img) and plt.show()\n",
        "    io.imsave('./inference_tile_{}.png'.format(id_), img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}